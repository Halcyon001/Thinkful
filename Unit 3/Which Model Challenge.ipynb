{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have a fairly substantial starting toolbox of supervised learning methods that you can use to tackle a host of exciting problems. To make sure all of these ideas are organized in your mind, please go through the list of problems below. For each, identify which supervised learning method(s) would be best for addressing that particular problem. Explain your reasoning and discuss your answers with your mentor.\n",
    "\n",
    "1. Predict the running times of prospective Olympic sprinters using data from the last 20 Olympics.\n",
    "2. You have more features (columns) than rows in your dataset.\n",
    "3. Identify the most important characteristic predicting likelihood of being jailed before age 20.\n",
    "4. Implement a filter to “highlight” emails that might be important to the recipient\n",
    "5. You have 1000+ features.\n",
    "6. Predict whether someone who adds items to their cart on a website will purchase the items.\n",
    "7. Your dataset dimensions are 982400 x 500\n",
    "8. Identify faces in an image.\n",
    "9. Predict which of three flavors of ice cream will be most popular with boys vs girls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. I would use a linear regression model because we are measuring a continuous value with some limited data since we just have olympic sprinters from the past 20 years. A linear regression is a simple model for a simple variable of interest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. I would try regression with regularization, because regularization has embedded feature selection, and if we have more columns than rows that means we have more features than observations (meaning at worst we have a limited number of extremely complicated observants), and we need to narrow down the data to the features that matter. I heard PLS is a good option in this situation too, because it performs regression on smaller subspaces of features instead of using the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. I would use a decision tree because the first node would find the answer to this question by creating a splitting rule based on the most important feature(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. I would use a Naive-Bayes model because it has seen success already in filtering emails for spam, and \"highlighting\" emails for importance is sort of the opposite of identifying emails for spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. With 1000+ features I would use regression with regularization in order to cut down on the number of features, since models that use L1 and L2 regularization combat overfitting and inherently implement feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. I would try a support vector machine or random forest. Whether or not someone buys something after adding the item to their cart seems like it would be hard to predict, and I'm not sure what kind of data we would have on them. Therefore, I would throw an optimized SVM or random forest at it and hope it got a good result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. I would use a random forest because we have many observations. The random forest can only predict things it has seen before, so with a lot of observations, the trees that make up the forest have a lot of examples to learn from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. I would use a random forest because the important thing is that we correctly identify a face. From the image of the face, we can identify different features on the face that define it, but we don't need to understand how it works, we just need it to get accurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. A support vector machine because we need a classifier, and an SVM is better at predicting a class than doing regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
