{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...         V21       V22       V23       V24  \\\n",
      "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
      "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
      "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
      "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
      "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
      "\n",
      "        V25       V26       V27       V28  Amount  Class  \n",
      "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "rawdata = pd.read_csv('../../datasets/creditcardfraud/creditcard.csv')\n",
    "\n",
    "print(rawdata.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Someone already performed PCA on the data, so the features are not correlated with each other. This can be verified by checking a correlation matrix of the data. For the record, Time is the number of seconds passed since the data began being collected (observations where Time = 0). Amount is the amount of the purchase, and Class is either 1 or 0. Class = 1 indicates a fraudulent transaction. Class = 0 indicates a legitimate transaction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rawdata.drop('Class', axis=1)\n",
    "y = rawdata['Class']\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a random forest, an SVM, a boosting classifier, and a logistic regression, and optimize them a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll implement a random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=50, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 10, min_samples_leaf=50, n_jobs=-1)\n",
    "rfc.fit(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yconfidences_rfc = rfc.predict_proba(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision-Recall Score: 0.86553\n"
     ]
    }
   ],
   "source": [
    "avg_precision_rfc = average_precision_score(ytest, yconfidences_rfc[:, 1])\n",
    "print('Average Precision-Recall Score: {0:0.5f}'.format(avg_precision_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=50, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [10, 20, 30], 'min_samples_leaf': [25, 50, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_params = {\n",
    "    'n_estimators' : [10, 20, 30],\n",
    "    'min_samples_leaf' : [25, 50, 100],\n",
    "}\n",
    "\n",
    "gridsearch_rfc_auc = GridSearchCV(rfc, rfc_params, cv=3, scoring='roc_auc')\n",
    "\n",
    "gridsearch_rfc_auc.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_leaf': 100, 'n_estimators': 30}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=100, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is where we'll retrieve the best params and add them to the model once the above cell finishes running\n",
    "print(gridsearch_rfc_auc.best_params_)\n",
    "rfc.set_params(**gridsearch_rfc_auc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "#create a linear support vector classifier model\n",
    "svc = LinearSVC()\n",
    "svc.get_params()\n",
    "\n",
    "svc.fit(xtrain, ytrain)\n",
    "yconfidences_svc = svc.decision_function(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.2, 0.8, 1]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the SVC parameters to test\n",
    "svc_params = {\n",
    "    'C' : [.2, .8, 1]\n",
    "}\n",
    "\n",
    "#search for the best parameters\n",
    "gridsearch_svc_auc = GridSearchCV(svc, svc_params, cv=3, scoring='roc_auc')\n",
    "\n",
    "gridsearch_svc_auc.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.2, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Retrieve the best parameters from the search and apply them to our model\n",
    "print(gridsearch_svc_auc.best_params_)\n",
    "svc.set_params(**gridsearch_svc_auc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#create a gradient boosting model\n",
    "gbc = GradientBoostingClassifier(max_features = 5)\n",
    "gbc.get_params()\n",
    "\n",
    "gbc.fit(xtrain, ytrain)\n",
    "yconfidences_gbc = gbc.decision_function(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=5, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'min_samples_split': [2, 3, 5], 'max_depth': [1, 3, 5, 8, 10], 'n_estimators': [100, 150, 200]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define parameters to test\n",
    "gbc_params = {\n",
    "    'min_samples_split' : [2, 3, 5],\n",
    "    'max_depth' : [1, 3, 5, 8, 10],\n",
    "    'n_estimators' : [100, 150, 200]\n",
    "}\n",
    "\n",
    "#search for the optimal parameters\n",
    "gridsearch_gbc_auc = GridSearchCV(gbc, gbc_params, cv=3, scoring='roc_auc')\n",
    "\n",
    "gridsearch_gbc_auc.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 8, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=8,\n",
       "              max_features=5, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the optimized parameters from the gridsearch\n",
    "print(gridsearch_gbc_auc.best_params_)\n",
    "gbc.set_params(**gridsearch_gbc_auc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cs': 10, 'class_weight': None, 'cv': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1.0, 'max_iter': 100, 'multi_class': 'ovr', 'n_jobs': -1, 'penalty': 'l2', 'random_state': None, 'refit': True, 'scoring': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=-1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "#create a logistic regression model\n",
    "#Selection of an optimized C value is BUILT IN to this model\n",
    "lrcv = LogisticRegressionCV(n_jobs=-1)\n",
    "print(lrcv.get_params())\n",
    "\n",
    "lrcv.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(rfc.predict_proba(xtest)[:, 1])\n",
    "print(rfc.predict(xtest))\n",
    "rfc.predict_proba(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier AUROC: 0.9991385425599261\n",
      "Support Vector Classifier AUROC: 0.8607375946387229\n",
      "Gradient Boosting Classifier AUROC: 0.8570422134723339\n",
      "Logistic Regression AUROC: 0.9469342216914423\n"
     ]
    }
   ],
   "source": [
    "#now test the rfc, svc, gbc, and lr(cv) on the test data\n",
    "#we have a random forest classifier, support vector machine, gradient boosting classifer, and logistic regression model\n",
    "from sklearn.metrics import roc_auc_score \n",
    "\n",
    "#sic rfc on test data\n",
    "rfc_roc_auc = roc_auc_score(ytest, rfc.predict_proba(xtest)[:, 1])\n",
    "print('Random Forest Classifier AUROC: ' + str(rfc_roc_auc))\n",
    "\n",
    "#sic svc on test data\n",
    "#the decision function returns the distance of a prediction from the hyperplane, I guess, which I guess is like confidence\n",
    "#since a higher distance from the hyperplane should mean higher confidence\n",
    "svc_roc_auc = roc_auc_score(ytest, svc.decision_function(xtest))\n",
    "print('Support Vector Classifier AUROC: ' + str(svc_roc_auc))\n",
    "\n",
    "#sic gbc on test data\n",
    "gbc_roc_auc = roc_auc_score(ytest, gbc.predict_proba(xtest)[:, 1])\n",
    "print('Gradient Boosting Classifier AUROC: ' + str(gbc_roc_auc))\n",
    "\n",
    "#sic lrcv on test data\n",
    "lrcv_roc_auc = roc_auc_score(ytest, lrcv.predict_proba(xtest)[:, 1])\n",
    "print('Logistic Regression AUROC: '  + str(lrcv_roc_auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999420666409185"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the random forest classifier does an extremely great job of predicting fraudulent credit card transactions correctly. Nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
