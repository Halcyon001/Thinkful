{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv((\n",
    "    \"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "    \"master/ESS_practice_data/ESSdata_Thinkful.csv\")).dropna()\n",
    "\n",
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "X = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=1)\n",
    "\n",
    "# Create training and test sets.\n",
    "#offset = int(X.shape[0] * 0.8)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "#X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "#X_test, y_test = X[offset:], y[offset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cntry', 'idno', 'year', 'tvtot', 'ppltrst', 'pplfair', 'pplhlp',\n",
       "       'happy', 'sclmeet', 'sclact', 'gndr', 'agea', 'partner'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.046493785484118456\n",
      "Percent Type II errors: 0.1727788859904864\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.06687116564417178\n",
      "Percent Type II errors: 0.17914110429447852\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(x_train)\n",
    "predict_test = clf.predict(x_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0, 1] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1 , 0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0, 1]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1, 0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partner</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>3700</td>\n",
       "      <td>303</td>\n",
       "      <td>4003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1126</td>\n",
       "      <td>1388</td>\n",
       "      <td>2514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>4826</td>\n",
       "      <td>1691</td>\n",
       "      <td>6517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     0.0   1.0   All\n",
       "partner                  \n",
       "0.0      3700   303  4003\n",
       "1.0      1126  1388  2514\n",
       "All      4826  1691  6517"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# Make importances relative to max importance.\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  0, 11, 10, 15, 13, 14,  7,  6,  2,  8,  4,  1,  3,  5,  9],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge \n",
    "\n",
    "Make it better. \n",
    "\n",
    "The only things we have to work with are the features (columns of X, our input), and the parameters for our model. Both of which are listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['year', 'tvtot', 'ppltrst', 'pplfair', 'pplhlp', 'happy', 'sclmeet',\n",
      "       'sclact', 'gndr', 'agea', 'CH', 'CZ', 'DE', 'ES', 'NO', 'SE'],\n",
      "      dtype='object') \n",
      "\n",
      " {'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 500, 'presort': 'auto', 'random_state': None, 'subsample': 1.0, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print(X.columns, '\\n'*2, clf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Applying more overfitting-prevention strategies like subsampling\n",
    "- More iterations\n",
    "- Trying a different loss function\n",
    "- Changing the structure of the weak learner: Allowing more leaves in the tree, or other modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradient boosting with trees (sklearn gradientboosting) continuous params:\n",
    "- learning_rate\n",
    "- max_depth\n",
    "- max_features?\n",
    "- max_leaf_nodes?\n",
    "- min_impurity_decrease/min_impurity_split/min_samples_leaf/min_samples_split/min_weight/fraction_leaf\n",
    "- n_estimators\n",
    "- subsample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8147, 16)\n",
      "(8147, 16)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "x_corrs = X.corr().abs()\n",
    "\n",
    "x_upper = x_corrs.where(np.triu(np.ones(x_corrs.shape), k=1).astype(bool))\n",
    "highly_corred = [column for column in x_upper.columns if any(x_upper[column] > .90)]\n",
    "\n",
    "X.drop(highly_corred, axis=1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#let's just do a gridsearch to optimize the gradient boost classifier\\nfrom sklearn.model_selection import GridSearchCV\\nparams = {\\n    'learning_rate' : [.1, .5, .9],\\n    'max_depth' : [1, 3, 5],\\n    'max_features' : ['auto','log2', 3, None],\\n    'n_estimators' : [100, 300, 500, 1000, 2000],\\n    'subsample' : [.1, .5, .9]\\n}\\n\\ngridsearch = GridSearchCV(clf, params, cv=3, scoring='r2')\\n\\ngridsearch.fit(x_train, y_train)\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#let's just do a gridsearch to optimize the gradient boost classifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {\n",
    "    'learning_rate' : [.1, .5, .9],\n",
    "    'max_depth' : [1, 3, 5],\n",
    "    'max_features' : ['auto','log2', 3, None],\n",
    "    'n_estimators' : [100, 300, 500, 1000, 2000],\n",
    "    'subsample' : [.1, .5, .9]\n",
    "}\n",
    "\n",
    "gridsearch = GridSearchCV(clf, params, cv=3, scoring='r2')\n",
    "\n",
    "gridsearch.fit(x_train, y_train)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(str(gridsearch.best_params_))\n",
    "bestparams = {\n",
    "    'learning_rate' : .1,\n",
    "    'max_depth' : 3,\n",
    "    'max_features' : None,\n",
    "    'n_estimators' : 100,\n",
    "    'subsample' : .9,\n",
    "}\n",
    "bestparams2 = {\n",
    "    'learning_rate' : .1,\n",
    "    'max_depth' : 3,\n",
    "    'max_features' : None,\n",
    "    'n_estimators' : 100,\n",
    "    'subsample' : .9,\n",
    "    'loss' : 'exponential'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='exponential', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=0.9, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.set_params(**bestparams2)\n",
    "\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04327144391591223\n",
      "Percent Type II errors: 0.18045112781954886\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.05460122699386503\n",
      "Percent Type II errors: 0.18650306748466258\n"
     ]
    }
   ],
   "source": [
    "predict_train = clf.predict(x_train)\n",
    "predict_test = clf.predict(x_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0, 1] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1 , 0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0, 1]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1, 0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R^2 of the optimized model was only very slightly better than the old model. The exponential loss function seemed to \n",
    "improve the score as well. The newer model improved the amount of false positives (Type 1 errors), but also increased the number of false negatives (Type 2 errors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Model\n",
    "Training set accuracy:\n",
    "Percent Type I errors: 0.046493785484118456\n",
    "Percent Type II errors: 0.1727788859904864\n",
    "\n",
    "Test set accuracy:\n",
    "Percent Type I errors: 0.06687116564417178\n",
    "Percent Type II errors: 0.17914110429447852"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Model\n",
    "Training set accuracy:\n",
    "Percent Type I errors: 0.04327144391591223\n",
    "Percent Type II errors: 0.18045112781954886\n",
    "\n",
    "Test set accuracy:\n",
    "Percent Type I errors: 0.05460122699386503\n",
    "Percent Type II errors: 0.18650306748466258"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
